\unchapter{Introduction}
The primary objective of this bachelor’s thesis is to design, implement, and evaluate an information technology–based analytical solution for predicting student academic performance, leveraging modern machine learning algorithms and explainable artificial intelligence techniques. This work focuses on supervised learning approaches and modern publicly available student datasets published after 2019 with the goal to develop predictive models with high accuracy and model explainability. In addition to generating accurate predictions, this research also aims to produce human-interpretable and actionable insights for evidence-based decision-making in educational settings, such as the early detection of at-risk students and other use cases.  

\textbf{Topicality of the problem:}  
Student Academic Performance Prediction Using Machine Learning Models

\textbf{Aim of the study:}  
To apply modern machine learning and explainability techniques to predict student academic performance using recent publicly available datasets, and to identify the most influential factors driving student success.

\textbf{Object of the study:}  
Academic performance data from recent public student datasets (Kaggle 2020–2023 datasets such as “Predict Students Dropout and Academic Success”).  

\textbf{Subject of the study:}  
The process of predicting and interpreting student performance using modern ML algorithms and explainability tools on 2020–2023 student datasets.

\textbf{Research problem:}  
Most existing studies use outdated datasets (e.g., UCI 2008), limiting relevance. There is a need to use modern datasets (2020–2023) and apply explainability methods to generate fresh, evidence-based insight into academic success factors. 

\textbf{Tasks of the study:}  
To reach the goal stated above, the bachelor’s thesis work has to accomplish the following research tasks:
1. Review modern theoretical and empirical developments in educational data mining, learning analytics, and student performance prediction.
2. Analyze supervised machine learning approaches commonly used in the literature to address the academic performance classification problem.
3. Collect and prepare publicly available student performance datasets that were published after 2019.
4. Design and implement a reproducible data preprocessing and feature engineering pipeline using Python-based tools.
5. Develop and train machine learning models for student performance prediction, including Logistic Regression, Random Forest, and Gradient Boosting.
6. Evaluate the performance of these models using standard classification metrics (ROC-AUC, precision, recall, F1-score, confusion matrices, etc.). 
7. Apply machine learning model explainability techniques to interpret predictions and to identify the key factors affecting academic success.
8. Develop actionable analytical recommendations for the improvement of academic performance monitoring and early intervention based on the results.


\textbf{Hypothesis:}  
Modern ML models combined with explainability techniques (SHAP/LIME), applied to recent 2020–2023 student datasets, can accurately predict academic performance and reveal key determinants of student success.

\textbf{Research methods:}  
Data collection from 2020–2023 public student datasets
Machine learning models
Explainability (SHAP/LIME)
ROC-AUC, F1-score
Dashboards/visualizations

\textbf{Approbation of the study:}  
Most existing studies use outdated datasets (e.g., UCI 2008), limiting relevance. There is a need to use modern datasets (2020–2023) and apply explainability methods to generate fresh, evidence-based insight into academic success factors.The scope of the bachelor’s thesis work includes a literature review on the most relevant aspects of the research, a definition of the applicable analytical methods and tools for the educational data analysis, a choice of recent and publicly available datasets of student data and the execution of the described predictive and interpretability methods in a unified computational environment. The educational performance data of students has become a popular data source for the academic analysis by higher education institutions since these data reflect the learning outcomes, engagement, and system challenges experienced by students in the learning process. The large volumes of data from the digital learning platforms and institutional information systems have accumulated, and, therefore, there is an opportunity to study these data to gain new insights about student performance and behavior. Predicting student performance is one of the most relevant tasks of learning analytics and educational data mining as it enables institutions to identify at-risk students and implement timely interventions. Well-performing prediction models can also support decision-making in academic advising, curriculum development, and resource allocation. The data-driven academic performance prediction is also an essential building block of student retention efforts and can be a source of data-based insights to improve the learning outcomes. Recent studies have shown that data-driven student performance prediction can be a significant factor in the improvement of institutional decision-making provided that the predictive models are accurate and interpretable. However, many existing studies are using an outdated data sources for this purpose. One of the most commonly used datasets in this research area is the UCI Student Performance dataset, which has been published more than 10 years ago. As the educational systems have undergone significant changes since then, especially after 2020, the analysis performed using the old dataset is not going to be as relevant as the analysis with a recent data. The student experience and academic performance have changed under the influence of digitalization, the introduction of blended and online learning formats, and other shifts in learning conditions and assessment types. Therefore, there is a research gap that can be addressed by the work of this thesis, which is to revisit the prediction of student academic performance with the application of a modern analytical solution with updated publicly available datasets. This work focuses explicitly on the application of recently published (2020-2023) datasets and does not use outdated sources of student data. Machine learning models have been shown to exhibit good predictive performance for the academic outcome prediction due to their capacity to model complex relationships between the multitude of student factors. Ensemble-based approaches such as Random Forest and Gradient Boosting are known to be highly competitive for capturing non-linear relationships between the demographic, academic, and behavioral factors. On the other hand, simple statistical models like Logistic Regression still serve as good baselines due to their transparency and stable probabilistic interpretation. A comparison of different families of models is to be performed to assess the predictive performance and explainability of different approaches. In addition to high accuracy, a critical issue for practical adoption of machine learning models into the data-informed educational decision-making is the lack of transparency. Black-box predictions with no accompanying explanation can reduce the trust in ML models among educational practitioners and administrators, as well as introduce ethical issues. For this reason, the work on explainable artificial intelligence has emerged as a critical direction of applied machine learning research. Explainability methods such as SHAP (Shapley Additive Explanations) and LIME (Local Interpretable Model-agnostic Explanations) can be used to interpret model predictions in a post-hoc manner by quantifying the individual contributions of each input feature to the output prediction. These approaches to explainability can be used to analyze complex ML models in an interpretable way to non-technical stakeholders and increase the accountability and practical usability of ML-based decision-support systems.

The research solution developed in this work has been implemented using the Python programming language because of its maturity, open-source libraries and tools for data analysis, machine learning, and visualization. Python is cross-platform, supports reproducibility, and is widely adopted in both academic research and industry practice, which makes it one of the most common choices for data analytics tasks in Python. Libraries like Pandas, NumPy, Scikit-learn, SHAP, and Matplotlib have been used to develop a modular, transparent, and easy-to-extend analytical pipeline that can be also easily adapted for other educational datasets. The research direction of this bachelor’s thesis work can be described as an integration of theoretical analysis, practical implementation, and experimental evaluation. The theoretical part involves the study of relevant background in the fields of educational data mining, supervised learning, and explainable AI. The practical part consists of the implementation of this theory into a practical predictive and explainability research framework using real-world educational datasets. The experimental evaluation focuses on the quantitative and qualitative comparison of the predictive performance and explainability of the developed models to ensure that the obtained results and insights are accurate, interpretable, and can be used in data-informed decision-making in educational settings.

The bachelor’s thesis has three main chapters. The first chapter discusses the theoretical background concerning the student performance prediction problem, educational data mining, machine learning classification methods, and explainable artificial intelligence. This chapter also reviews the state of research on this topic and establishes the context and a foundation for the thesis work. The second chapter outlines the research methodology, dataset selection, data preprocessing, and feature engineering that have been performed for this research. This chapter also includes a description of the experimental design and the justifications of the applied analytical approaches. The third chapter of the thesis is related to the model development, evaluation of the predictive performance, and the explainability analysis. This chapter compares the predictive results of different models, provides interpretations for the most influential academic performance factors, and discusses the practical implications of the obtained results. The conclusion summarizes the results of this research, outlines the main theoretical and practical contributions of this work, and formulates the recommendations for future work. In general, this research work is intended to support the educational analytics field by providing an example of how the modern machine learning models, when paired with explainability approaches and recent educational datasets, can produce not only highly accurate but also transparent and actionable insights into student academic performance.

